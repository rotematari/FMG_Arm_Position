{
    "config": {
        "name": "TransformerModel",
        "d_model_transformer": 512,
        "num_layers_transformer": 8,
        "fc_dropout_transformer": 0.4753571532049581,
        "d_ff_transformer": 1024,
        "transformer_n_head": 4,
        "head_dropout_transformer": 0.1790550473839461,
        "activation": "gelu",
        "use_learnable_positional_encoding": true,
        "dropout": 0.13998996632720118,
        "learning_rate": 0.00023864188780056057,
        "weight_decay": 1.0025956902289577e-05,
        "batch_size": 64,
        "sequence_length": 64,
        "epochs": 10
    },
    "loss": 0.572604717577205,
    "wrist_error": 0.1674010157585144,
    "best_epoch": 9
}